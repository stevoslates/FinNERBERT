{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transforming into NER Dataset\n",
    "Now we have the data into the format we want, we still need to put it into the format of an NER datast. We need it in the format IOB (Inside, Out, Beginning) format for each word. But first we need to create the tags that we want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "charities_train = pd.read_csv(\"realKieData/charities/train.csv\")\n",
    "charities_validation = pd.read_csv(\"realKieData/charities/val.csv\")\n",
    "charities_test = pd.read_csv(\"realKieData/charities/test.csv\")\n",
    "\n",
    "nda_train = pd.read_csv(\"realKieData/nda/train.csv\")\n",
    "nda_validation = pd.read_csv(\"realKieData/nda/val.csv\")\n",
    "nda_test = pd.read_csv(\"realKieData/nda/test.csv\")\n",
    "\n",
    "fcc_train = pd.read_csv(\"realKieData/fcc/train.csv\")\n",
    "fcc_validation = pd.read_csv(\"realKieData/fcc/val.csv\")\n",
    "fcc_test = pd.read_csv(\"realKieData/fcc/test.csv\")\n",
    "\n",
    "rc_train = pd.read_csv(\"realKieData/rc/train.csv\")\n",
    "rc_validation = pd.read_csv(\"realKieData/rc/val.csv\")\n",
    "rc_test = pd.read_csv(\"realKieData/rc/test.csv\")\n",
    "\n",
    "s1_train = pd.read_csv(\"realKieData/s1/train.csv\")\n",
    "s1_validation = pd.read_csv(\"realKieData/s1/val.csv\")\n",
    "s1_test = pd.read_csv(\"realKieData/s1/test.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "charities_train['labels'] = charities_train['labels'].apply(json.loads)\n",
    "charities_validation['labels'] = charities_validation['labels'].apply(json.loads)\n",
    "charities_test['labels'] = charities_test['labels'].apply(json.loads)\n",
    "\n",
    "nda_train['labels'] = nda_train['labels'].apply(json.loads)\n",
    "nda_validation['labels'] = nda_validation['labels'].apply(json.loads)\n",
    "nda_test['labels'] = nda_test['labels'].apply(json.loads)\n",
    "\n",
    "fcc_train['labels'] = fcc_train['labels'].apply(json.loads)\n",
    "fcc_validation['labels'] = fcc_validation['labels'].apply(json.loads)\n",
    "fcc_test['labels'] = fcc_test['labels'].apply(json.loads)\n",
    "\n",
    "rc_train['labels'] = rc_train['labels'].apply(json.loads)\n",
    "rc_validation['labels'] = rc_validation['labels'].apply(json.loads)\n",
    "rc_test['labels'] = rc_test['labels'].apply(json.loads)\n",
    "\n",
    "s1_train['labels'] = s1_train['labels'].apply(json.loads)\n",
    "s1_validation['labels'] = s1_validation['labels'].apply(json.loads)\n",
    "s1_test['labels'] = s1_test['labels'].apply(json.loads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': 'Charity Name',\n",
       " 'start': 2950,\n",
       " 'end': 2970,\n",
       " 'text': 'MICKLEHAM ALMSHOUSES'}"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "charities_train.iloc[0]['labels'][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'MICKLEHAM ALMSHOUSES'"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "charities_train.text[0][2950:2970]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Investigating different entities "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "def count_labels(dataset, column_name='labels'):\n",
    "    all_labels = []\n",
    "    \n",
    "    # Iterate over each row and parse the JSON-like strings\n",
    "    for row in dataset[column_name]:\n",
    "        try:\n",
    "            # Parse the JSON-like string\n",
    "            # Extract labels and add to the all_labels list\n",
    "            for item in row:\n",
    "                all_labels.append(item['label'])\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"Error decoding JSON in row: {row} - {e}\")\n",
    "    \n",
    "    # Count the occurrences of each label\n",
    "    label_counts = Counter(all_labels)\n",
    "    \n",
    "    # Print the counts\n",
    "    for label, count in label_counts.items():\n",
    "        print(f\"{label}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Charity Name: 4250\n",
      "Charity Registered Number: 729\n",
      "Year Ended: 3644\n",
      "Accounting Basis: 231\n",
      "Independent Examiner Name: 398\n",
      "Examination Date: 211\n",
      "Independent Examiner Street Address: 534\n",
      "Independent Examiner City: 549\n",
      "Independent Examiner Postal Code: 515\n",
      "Net Income at Current Year End: 162\n",
      "Net Income at Previous Year End: 165\n",
      "Net Assets at Current Year End: 242\n",
      "Net Assets at Previous Year End: 231\n",
      "Cash In Hand at Current Year End: 281\n",
      "Cash In Hand at Previous Year End: 273\n",
      "Principal Office Street Address: 294\n",
      "Principal Office City: 295\n",
      "Principal Office Postal Code: 283\n",
      "Trustee Name: 3510\n",
      "Trustee Title: 1051\n",
      "Objectives and Activities: 270\n",
      "Independent Examiner Company: 447\n",
      "Bank Name: 233\n",
      "Named Donor: 445\n",
      "Company Number: 181\n",
      "Named Employee: 52\n",
      "Event Name: 136\n",
      "Project Name: 107\n"
     ]
    }
   ],
   "source": [
    "count_labels(charities_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jurisdiction: 243\n",
      "Party: 522\n",
      "Effective Date: 237\n"
     ]
    }
   ],
   "source": [
    "count_labels(nda_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Line Item - Description: 10170\n",
      "Line Item - Days: 8810\n",
      "Line Item - Rate: 11980\n",
      "Line Item - Start Date: 11889\n",
      "Line Item - End Date: 6010\n",
      "Agency: 399\n",
      "Advertiser: 608\n",
      "Gross Total: 496\n",
      "Net Amount Due: 375\n",
      "Agency Commission: 224\n",
      "Payment Terms: 254\n"
     ]
    }
   ],
   "source": [
    "count_labels(fcc_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Header) Contract Area Description: 144\n",
      "Contract Area Description: 574\n",
      "(Header)Governing law: 140\n",
      "Governing law: 143\n",
      "(Header)Hardship clause or force majeure: 118\n",
      "Hardship clause or force majeure: 158\n",
      "(Header)Reporting requirements: 301\n",
      "Reporting requirements: 762\n",
      "(Header)Environmental protections: 124\n",
      "Environmental protections: 296\n",
      "(Header)Income tax: rate: 101\n",
      "Income tax: rate: 101\n",
      "(Header)Term: 165\n",
      "Term: 217\n",
      "Renewal or extension of term: 271\n",
      "Type: 202\n",
      "Date Signed: 171\n",
      "Participants: 518\n",
      "Country: 243\n",
      "Project: 117\n",
      "Water use: 72\n",
      "Signatories, company: 283\n",
      "(Header)Water use: 19\n"
     ]
    }
   ],
   "source": [
    "count_labels(rc_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Company Officer: 1528\n",
      "Company Officer Title: 1547\n",
      "Risk Clauses: 14487\n",
      "(Header) Risks To The Business: 194\n",
      "(Header) Description of Securities: 220\n",
      "Description of Securities (1st Para): 226\n",
      "(Header) Dividend Policy: 180\n",
      "Dividend Policy (1st Para): 181\n",
      "(Header) Prospectus Summary: 191\n",
      "Prospectus Summary (1st Para): 1852\n",
      "Joint Book Runners: 352\n",
      "Title of Security Registered: 537\n",
      "Amount Registered: 524\n",
      "Max Price: 280\n",
      "Date of Prospectus: 187\n",
      "Company Name: 195\n",
      "Company Address: 192\n",
      "Agent Name: 190\n",
      "Agent Address: 190\n",
      "Agent Telephone: 183\n",
      "EIN: 187\n",
      "Attorney Names: 738\n",
      "Law Firm Name: 382\n",
      "Law Firm Address: 527\n"
     ]
    }
   ],
   "source": [
    "count_labels(s1_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning text, removing blank lines and adjusting offsets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_empty_labels(df, dataset_name, split):\n",
    "    # Filter out rows where labels are equal to '[]' and print them\n",
    "    empty_labels_rows = df[df['labels'] == '[]']\n",
    "    if not empty_labels_rows.empty:\n",
    "        print(f\"Removed rows from {dataset_name} {split}:\")\n",
    "        #print(empty_labels_rows)\n",
    "    \n",
    "    return df[df['labels'] != '[]']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "charities_train = remove_empty_labels(charities_train, 'charities', 'train')\n",
    "charities_validation = remove_empty_labels(charities_validation, 'charities', 'validation')\n",
    "charities_test = remove_empty_labels(charities_test, 'charities', 'test')\n",
    "\n",
    "nda_train = remove_empty_labels(nda_train, 'nda', 'train')\n",
    "nda_validation = remove_empty_labels(nda_validation, 'nda', 'validation')\n",
    "nda_test = remove_empty_labels(nda_test, 'nda', 'test')\n",
    "\n",
    "fcc_train = remove_empty_labels(fcc_train, 'fcc', 'train')\n",
    "fcc_validation = remove_empty_labels(fcc_validation, 'fcc', 'validation')\n",
    "fcc_test = remove_empty_labels(fcc_test, 'fcc', 'test')\n",
    "\n",
    "rc_train = remove_empty_labels(rc_train, 'rc', 'train')\n",
    "rc_validation = remove_empty_labels(rc_validation, 'rc', 'validation')\n",
    "rc_test = remove_empty_labels(rc_test, 'rc', 'test')\n",
    "\n",
    "s1_train = remove_empty_labels(s1_train, 's1', 'train')\n",
    "s1_validation = remove_empty_labels(s1_validation, 's1', 'validation')\n",
    "s1_test = remove_empty_labels(s1_test, 's1', 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop all columns apart from text and labels\n",
    "charities_train = charities_train[['text', 'labels']]\n",
    "charities_validation = charities_validation[['text', 'labels']]\n",
    "charities_test = charities_test[['text', 'labels']]\n",
    "\n",
    "nda_train = nda_train[['text', 'labels']]\n",
    "nda_validation = nda_validation[['text', 'labels']]\n",
    "nda_test = nda_test[['text', 'labels']]\n",
    "\n",
    "fcc_train = fcc_train[['text', 'labels']]\n",
    "fcc_validation = fcc_validation[['text', 'labels']]\n",
    "fcc_test = fcc_test[['text', 'labels']]\n",
    "\n",
    "rc_train = rc_train[['text', 'labels']]\n",
    "rc_validation = rc_validation[['text', 'labels']]\n",
    "rc_test = rc_test[['text', 'labels']]\n",
    "\n",
    "s1_train = s1_train[['text', 'labels']]\n",
    "s1_validation = s1_validation[['text', 'labels']]\n",
    "s1_test = s1_test[['text', 'labels']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original text: hello    h\n",
      "Cleaned text: hello h\n",
      "Offset map: [0, 0, 0, 0, 0, 5, 9]\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "#Not getting used\n",
    "def clean_text_with_offsets(text):\n",
    "    \"\"\"\n",
    "    Clean the text by replacing multiple spaces with a single space\n",
    "    and update the offsets accordingly.\n",
    "    \"\"\"\n",
    "    clean_text = []\n",
    "    offset_map = []\n",
    "    current_offset = 0\n",
    "    \n",
    "    # Replace multiple spaces with a single space\n",
    "    for match in re.finditer(r'\\S+|\\s+', text):\n",
    "        token = match.group(0)\n",
    "        if token.isspace():\n",
    "            if clean_text and clean_text[-1] != ' ':\n",
    "                clean_text.append(' ')\n",
    "                offset_map.append(current_offset)\n",
    "        else:\n",
    "            clean_text.append(token)\n",
    "            offset_map.extend([current_offset] * len(token))\n",
    "        current_offset += len(token)\n",
    "    \n",
    "    return ''.join(clean_text).strip(), offset_map\n",
    "\n",
    "\n",
    "text = \"hello    h\"\n",
    "\n",
    "cleaned_text, offset_map = clean_text_with_offsets(text)\n",
    "\n",
    "print(\"Original text:\", text)\n",
    "print(\"Cleaned text:\", cleaned_text)\n",
    "print(\"Offset map:\", offset_map)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the entities \n",
    "We only use some of the labels to create 4 entities for the model initally. PER (Person), ORG (Orginisation), LOC (Location), FIN (Finance - monetary amounts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to make the label to entity mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_to_entity = {\n",
    "    \"Charity Name\": \"ORG\",\n",
    "    \"Bank Name\": \"ORG\",\n",
    "    \"Party\": \"ORG\",\n",
    "    \"Agency\": \"ORG\",\n",
    "    \"Participants\": \"ORG\",\n",
    "    \"Law Firm Name\": \"ORG\",\n",
    "    \"Company Name\": \"ORG\",\n",
    "    \"Joint Book Runners\": \"ORG\",\n",
    "    \"Company Officer\": \"PER\",\n",
    "    \"Attorney names\" : \"PER\",\n",
    "    \"Independent Examiner Name\": \"PER\",\n",
    "    \"Trustee Name\": \"PER\",\n",
    "    \"Signatories\": \"PER\",\n",
    "    \"Company\": \"PER\",\n",
    "    \"Date Signed\": \"DAT\",\n",
    "    \"Effective Date\": \"DAT\",\n",
    "    \"Examination Date\": \"DAT\",\n",
    "    \"Year Ended\": \"DAT\",\n",
    "    \"Date of Prospectus\": \"DAT\",\n",
    "    \"Line Item - Start Date\": \"DAT\",\n",
    "    \"Line Item - End Date\": \"DAT\",\n",
    "    \"Independent Examiner City\": \"LOC\",\n",
    "    \"Principal Office City\": \"LOC\",\n",
    "    \"Jurisdiction\": \"LOC\",\n",
    "    \"Country\": \"LOC\",\n",
    "    \"Governing Law\": \"LOC\",\n",
    "    \"Net Income at Current Year End\": \"FIN\",\n",
    "    \"Net Income at Previous Year End\": \"FIN\",\n",
    "    \"Net Assets at Current Year End\": \"FIN\",\n",
    "    \"Net Assets at Previous Year End\": \"FIN\",\n",
    "    \"Cash In Hand at Current Year End\": \"FIN\",\n",
    "    \"Cash In Hand at Previous Year End\": \"FIN\",\n",
    "    \"Max Price\": \"FIN\",\n",
    "    \"Net Amount Due\": \"FIN\",\n",
    "    \"Gross Total\": \"FIN\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from transformers import BertTokenizerFast\n",
    "\n",
    "#Using BERT fast tokenizer\n",
    "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')\n",
    "\n",
    "\n",
    "def label_tokens(labels, tokenized_inputs, token_labels):\n",
    "    for label in labels:\n",
    "        start_char = label['start']\n",
    "        end_char = label['end']\n",
    "        label_text = label['label']\n",
    "        \n",
    "        if label_text in label_to_entity:\n",
    "            entity = label_to_entity[label_text]\n",
    "            \n",
    "            for idx, (start, end) in enumerate(tokenized_inputs['offset_mapping']):\n",
    "                if start >= start_char and end <= end_char:\n",
    "                    # Assign B-<entity> for the beginning token and I-<entity> for inside tokens\n",
    "                    if start == start_char:\n",
    "                        token_labels[idx] = f\"B-{entity}\"\n",
    "                    else:\n",
    "                        token_labels[idx] = f\"I-{entity}\"\n",
    "                    \n",
    "    return token_labels\n",
    "\n",
    "def process_dataframe(dataframe):\n",
    "    results = []\n",
    "\n",
    "    for index, row in dataframe.iterrows():\n",
    "        passage_id = index  # Using the index as the passage ID\n",
    "        text = row['text']\n",
    "        labels = row['labels']\n",
    "        \n",
    "        tokenized_inputs = tokenizer(text, return_offsets_mapping=True, truncation=True, max_length=512)\n",
    "        \n",
    "        token_labels = [\"O\"] * len(tokenized_inputs['input_ids'])\n",
    "        \n",
    "        token_labels = label_tokens(labels, tokenized_inputs, token_labels)\n",
    "        \n",
    "        for token, label in zip(tokenizer.convert_ids_to_tokens(tokenized_inputs['input_ids']), token_labels):\n",
    "            results.append({\n",
    "                'Passage_ID': passage_id,\n",
    "                'Token': token,\n",
    "                'Label': label\n",
    "            })\n",
    "\n",
    "    # Create a DataFrame from the results\n",
    "    results_df = pd.DataFrame(results)\n",
    "    \n",
    "    return results_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "charities_test_labeled = process_dataframe(charities_test)\n",
    "charities_train_labeled = process_dataframe(charities_train)\n",
    "charities_validation_labeled = process_dataframe(charities_validation)\n",
    "\n",
    "nda_test_labeled = process_dataframe(nda_test)\n",
    "nda_train_labeled = process_dataframe(nda_train)\n",
    "nda_validation_labeled = process_dataframe(nda_validation)\n",
    "\n",
    "fcc_test_labeled = process_dataframe(fcc_test)\n",
    "fcc_train_labeled = process_dataframe(fcc_train)\n",
    "fcc_validation_labeled = process_dataframe(fcc_validation)\n",
    "\n",
    "rc_test_labeled = process_dataframe(rc_test)\n",
    "rc_train_labeled = process_dataframe(rc_train)\n",
    "rc_validation_labeled = process_dataframe(rc_validation)\n",
    "\n",
    "s1_test_labeled = process_dataframe(s1_test)\n",
    "s1_train_labeled = process_dataframe(s1_train)\n",
    "s1_validation_labeled = process_dataframe(s1_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "charities_train_labeled = process_dataframe(charities_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Passage_ID</th>\n",
       "      <th>Token</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[CLS]</td>\n",
       "      <td>B-ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>mick</td>\n",
       "      <td>B-ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>##le</td>\n",
       "      <td>I-ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>##ham</td>\n",
       "      <td>I-ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>al</td>\n",
       "      <td>I-ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163385</th>\n",
       "      <td>321</td>\n",
       "      <td>ms</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163386</th>\n",
       "      <td>321</td>\n",
       "      <td>.</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163387</th>\n",
       "      <td>321</td>\n",
       "      <td>diane</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163388</th>\n",
       "      <td>321</td>\n",
       "      <td>ru</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163389</th>\n",
       "      <td>321</td>\n",
       "      <td>[SEP]</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>163390 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Passage_ID  Token  Label\n",
       "0                0  [CLS]  B-ORG\n",
       "1                0   mick  B-ORG\n",
       "2                0   ##le  I-ORG\n",
       "3                0  ##ham  I-ORG\n",
       "4                0     al  I-ORG\n",
       "...            ...    ...    ...\n",
       "163385         321     ms      O\n",
       "163386         321      .      O\n",
       "163387         321  diane      O\n",
       "163388         321     ru      O\n",
       "163389         321  [SEP]      O\n",
       "\n",
       "[163390 rows x 3 columns]"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "charities_train_labeled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "O        93942\n",
       "I-ORG     3035\n",
       "B-ORG      576\n",
       "I-DAT      565\n",
       "B-DAT      184\n",
       "B-PER        1\n",
       "I-PER        1\n",
       "Name: Label, dtype: int64"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1_train_labeled.Label.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next Step: Split it into sentences with berts context length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[CLS], charity, commission, number, -, 2004, ...</td>\n",
       "      <td>[O, O, O, O, O, O, O, B-ORG, I-ORG, I-ORG, I-O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[governance, and, management, the, charity, wa...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[charity, during, the, period, were, as, follo...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, B-PER, I-PER, I-PER, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[##hea, ##th, village, hall, for, use, by, loc...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[vanessa, big, ##gs, (, from, 2nd, april, 2019...</td>\n",
       "      <td>[B-PER, I-PER, I-PER, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>[as, our, chairman, mentioned, in, last, year,...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>[auditor, ##s, 13, to, 14, statement, of, fina...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>[trustees, stephanie, owen, joanna, philip, ma...</td>\n",
       "      <td>[O, B-PER, I-PER, B-PER, I-PER, B-PER, I-PER, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>[when, we, said, farewell, to, our, children, ...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>[##end, ,, hail, ##ing, ,, high, ##am, ,, ho, ...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>129 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Sentence  \\\n",
       "0    [[CLS], charity, commission, number, -, 2004, ...   \n",
       "1    [governance, and, management, the, charity, wa...   \n",
       "2    [charity, during, the, period, were, as, follo...   \n",
       "3    [##hea, ##th, village, hall, for, use, by, loc...   \n",
       "4    [vanessa, big, ##gs, (, from, 2nd, april, 2019...   \n",
       "..                                                 ...   \n",
       "124  [as, our, chairman, mentioned, in, last, year,...   \n",
       "125  [auditor, ##s, 13, to, 14, statement, of, fina...   \n",
       "126  [trustees, stephanie, owen, joanna, philip, ma...   \n",
       "127  [when, we, said, farewell, to, our, children, ...   \n",
       "128  [##end, ,, hail, ##ing, ,, high, ##am, ,, ho, ...   \n",
       "\n",
       "                                                Labels  \n",
       "0    [O, O, O, O, O, O, O, B-ORG, I-ORG, I-ORG, I-O...  \n",
       "1    [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
       "2    [O, O, O, O, O, O, O, O, B-PER, I-PER, I-PER, ...  \n",
       "3    [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
       "4    [B-PER, I-PER, I-PER, O, O, O, O, O, O, O, O, ...  \n",
       "..                                                 ...  \n",
       "124  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
       "125  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
       "126  [O, B-PER, I-PER, B-PER, I-PER, B-PER, I-PER, ...  \n",
       "127  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
       "128  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
       "\n",
       "[129 rows x 2 columns]"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from transformers import BertTokenizerFast\n",
    "\n",
    "# Initialize the tokenize\n",
    "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')\n",
    "\n",
    "def group_tokens_to_sentences(df, max_length=512):\n",
    "    sentences = []\n",
    "    labels = []\n",
    "    current_sentence = []\n",
    "    current_labels = []\n",
    "    current_length = 0\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        token = row['Token']\n",
    "        label = row['Label']\n",
    "        \n",
    "        token_length = len(tokenizer.encode(token, add_special_tokens=False))\n",
    "        \n",
    "        if current_length + token_length + 2 > max_length:\n",
    "            sentences.append(current_sentence)\n",
    "            labels.append(current_labels)\n",
    "            current_sentence = []\n",
    "            current_labels = []\n",
    "            current_length = 0\n",
    "        \n",
    "        current_sentence.append(token)\n",
    "        current_labels.append(label)\n",
    "        current_length += token_length\n",
    "    \n",
    "    if current_sentence:\n",
    "        sentences.append(current_sentence)\n",
    "        labels.append(current_labels)\n",
    "    \n",
    "    return sentences, labels\n",
    "\n",
    "sentences, sentence_labels = group_tokens_to_sentences(charities_test_labeled)\n",
    "\n",
    "sentence_df = pd.DataFrame({\n",
    "    'Sentence': sentences,\n",
    "    'Labels': sentence_labels\n",
    "})\n",
    "\n",
    "# Display the new DataFrame\n",
    "sentence_df\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
